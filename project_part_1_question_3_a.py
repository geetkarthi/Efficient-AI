# -*- coding: utf-8 -*-
"""Project part 1 - Question 3 - a.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bcBbQ3HLea6zxsx3J-qZbq7XQ1rOg-HJ
"""

import numpy as np
import tensorflow as tf
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score

# Load the Iris dataset
data = load_iris()
X = data.data
y = data.target

# Split data into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Standardize the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_val = scaler.transform(X_val)

# Define the neural network model
def create_model(input_shape):
    model = tf.keras.Sequential([
        tf.keras.layers.Dense(16, activation='relu', input_shape=(input_shape,)),
        tf.keras.layers.Dense(8, activation='relu'),
        tf.keras.layers.Dense(3, activation='softmax')
    ])
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return model

# Train and evaluate the model with a given feature subset
def evaluate_feature_subset(X_train, X_val, y_train, y_val, feature_indices):
    # Create model with the specific input shape
    model = create_model(len(feature_indices))

    # Train the model
    model.fit(X_train[:, feature_indices], y_train, epochs=50, batch_size=8, verbose=0)

    # Evaluate the model
    y_pred = np.argmax(model.predict(X_val[:, feature_indices]), axis=1)
    accuracy = accuracy_score(y_val, y_pred)
    return accuracy

# Backward search wrapper-based feature selection with performance reporting
def backward_search(X_train, X_val, y_train, y_val):
    n_features = X_train.shape[1]
    current_features = list(range(n_features))
    best_accuracy = 0
    best_features = current_features.copy()
    performance_log = []  # Store performance at each step

    while len(current_features) > 1:
        accuracies = []

        # Try removing each feature one at a time
        for feature in current_features:
            temp_features = current_features.copy()
            temp_features.remove(feature)
            accuracy = evaluate_feature_subset(X_train, X_val, y_train, y_val, temp_features)
            accuracies.append((accuracy, temp_features))

        # Find the feature removal that gives the highest accuracy
        best_subset_accuracy, best_subset = max(accuracies, key=lambda x: x[0])

        # Log the performance for this subset
        performance_log.append({
            "removed_feature": list(set(current_features) - set(best_subset))[0],
            "features_left": best_subset,
            "accuracy": best_subset_accuracy
        })

        # Update the best features if the accuracy is improved
        if best_subset_accuracy > best_accuracy:
            best_accuracy = best_subset_accuracy
            best_features = best_subset
            current_features = best_subset
        else:
            break  # Stop if removing features doesn't improve accuracy

    return best_features, best_accuracy, performance_log

# Perform backward feature selection
best_features, best_accuracy, performance_log = backward_search(X_train, X_val, y_train, y_val)

# Output the performance log
print("Performance after each feature drop:")
for step in performance_log:
    print(f"Removed Feature: {step['removed_feature']}, Features Left: {step['features_left']}, Validation Accuracy: {step['accuracy']:.4f}")

print("\nBest feature subset (0-indexed):", best_features)
print("Best validation accuracy with selected features:", best_accuracy)